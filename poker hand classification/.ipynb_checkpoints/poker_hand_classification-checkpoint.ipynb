{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each record is an example of a hand consisting of five playing cards drawn from a standard deck of 52. Each card is described using two attributes (suit and rank), for a total of 10 predictive attributes.\n",
    "\n",
    "* ranks (C1, C2, C3, C4, C5)    \n",
    "  - 1: Ace  \n",
    "  - 2-10: 2-10  \n",
    "  - 11: Jack  \n",
    "  - 12: Queen  \n",
    "  - 13: King  \n",
    "* suits (S1, S2, S3, S4, S5)   \n",
    "  - 1: Hearts  \n",
    "  - 2: Spades  \n",
    "  - 3: Diamonds  \n",
    "  - 4: Clubs  \n",
    "* hand  \n",
    "  - 0: Nothing in hand; not a recognized poker hand \n",
    "  - 1: One pair; one pair of equal ranks within five cards\n",
    "  - 2: Two pairs; two pairs of equal ranks within five cards\n",
    "  - 3: Three of a kind; three equal ranks within five cards\n",
    "  - 4: Straight; five cards, sequentially ranked with no gaps\n",
    "  - 5: Flush; five cards with the same suit\n",
    "  - 6: Full house; pair + different rank three of a kind\n",
    "  - 7: Four of a kind; four equal ranks within five cards\n",
    "  - 8: Straight flush; straight + flush\n",
    "  - 9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data: (1000000, 11)\n",
      "Training data: (25010, 11)\n",
      "-----\n",
      "Training Hand\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S1  C1  S2  C2  S3  C3  S4  C4  S5  C5  hand\n",
       "0   1  10   1  11   1  13   1  12   1   1     9\n",
       "1   2  11   2  13   2  10   2  12   2   1     9\n",
       "2   3  12   3  11   3  13   3  10   3   1     9\n",
       "3   4  10   4  11   4   1   4  13   4  12     9\n",
       "4   4   1   4  13   4  12   4  11   4  10     9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset location\n",
    "testing_data_location = \"./dataset/poker-hand-testing.data\"\n",
    "training_data_location = \"./dataset/poker-hand-training-true.data\"\n",
    "\n",
    "# assign column names to the dataset attributes\n",
    "names = ['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5','hand']\n",
    "\n",
    "# get testing & training data\n",
    "testing = pd.read_csv(testing_data_location, names=names, sep=',', header=None)\n",
    "training = pd.read_csv(training_data_location, names=names, sep=',', header=None)\n",
    "\n",
    "print(\"Testing data:\", testing.shape)\n",
    "print(\"Training data:\", training.shape)\n",
    "\n",
    "# show the first five columns of the training hand\n",
    "print(\"-----\")\n",
    "print(\"Training Hand\")\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Hand\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S1  C1  S2  C2  S3  C3  S4  C4  S5  C5  hand\n",
       "0   1   1   1  13   2   4   2   3   1  12     0\n",
       "1   3  12   3   2   3  11   4   5   2   5     1\n",
       "2   1   9   4   6   1   4   3   2   3   9     1\n",
       "3   1   4   3  13   2  13   2   1   3   6     1\n",
       "4   3  10   2   7   1   2   2  11   4   9     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first five columns of the testing hand\n",
    "print(\"Testing Hand\")\n",
    "testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate dataset attributes (X) from Class (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training X\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S1  C1  S2  C2  S3  C3  S4  C4  S5  C5\n",
       "0   1  10   1  11   1  13   1  12   1   1\n",
       "1   2  11   2  13   2  10   2  12   2   1\n",
       "2   3  12   3  11   3  13   3  10   3   1\n",
       "3   4  10   4  11   4   1   4  13   4  12\n",
       "4   4   1   4  13   4  12   4  11   4  10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate first ten columns (X) from eleven'th column for training set\n",
    "X_train = training.iloc[:,0:10]\n",
    "Y_train = training.iloc[:,10]\n",
    "\n",
    "# ...for testing set\n",
    "X_test = testing.iloc[:,0:10]\n",
    "Y_test = testing.iloc[:,10]\n",
    "\n",
    "# show first five columns of training X\n",
    "print(\"training X\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9\n",
       "1    9\n",
       "2    9\n",
       "3    9\n",
       "4    9\n",
       "Name: hand, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first five columns of training Y\n",
    "print(\"training Y\")\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show unique Class values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8, 1, 0, 4, 3, 2, 5, 6, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show unique Class categories\n",
    "Y_train.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# fit only for training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# transform training and testing data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3 layers of 10 nodes each + 1000 iterations\n",
    "mlp = MLPClassifier(solver='adam', hidden_layer_sizes=(20, 20), max_iter=2000, activation='tanh', learning_rate_init=0.02)\n",
    "\n",
    "# train algorithm on training data\n",
    "mlp.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# make predictions\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[442199  58884      0      0     10    112      0      0      4      0]\n",
      " [117441 302291   2169    506     34     37      0      4     16      0]\n",
      " [  1697  31549  13362   1007      5      0      2      0      0      0]\n",
      " [   863   5465    643  14141      0      0      7      2      0      0]\n",
      " [  2216   1653      0      0     14      0      0      0      2      0]\n",
      " [  1222    155      0      0      1    555      0      0     52     11]\n",
      " [     0    108    516    798      0      0      2      0      0      0]\n",
      " [     0      0     12    214      0      0      4      0      0      0]\n",
      " [     3      7      0      0      1      0      0      0      1      0]\n",
      " [     3      0      0      0      0      0      0      0      0      0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83    501209\n",
      "           1       0.76      0.72      0.73    422498\n",
      "           2       0.80      0.28      0.42     47622\n",
      "           3       0.85      0.67      0.75     21121\n",
      "           4       0.22      0.00      0.01      3885\n",
      "           5       0.79      0.28      0.41      1996\n",
      "           6       0.13      0.00      0.00      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.01      0.08      0.02        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.77      0.77      0.77   1000000\n",
      "   macro avg       0.43      0.29      0.32   1000000\n",
      "weighted avg       0.77      0.77      0.76   1000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with the other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Using Random Forest : 0.614135\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.81      0.71    501209\n",
      "           1       0.58      0.49      0.53    422498\n",
      "           2       0.39      0.00      0.01     47622\n",
      "           3       0.49      0.00      0.01     21121\n",
      "           4       0.31      0.00      0.00      3885\n",
      "           5       1.00      0.00      0.01      1996\n",
      "           6       0.00      0.00      0.00      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.61      0.61      0.61   1000000\n",
      "   macro avg       0.34      0.13      0.13   1000000\n",
      "weighted avg       0.59      0.61      0.58   1000000\n",
      "\n",
      "[[405379  95814     11      3      2      0      0      0      0      0]\n",
      " [213748 208485    225     31      9      0      0      0      0      0]\n",
      " [ 12277  35132    201     12      0      0      0      0      0      0]\n",
      " [  3450  17566     46     59      0      0      0      0      0      0]\n",
      " [   353   3522      5      0      5      0      0      0      0      0]\n",
      " [  1807    183      0      0      0      6      0      0      0      0]\n",
      " [    57   1332     28      7      0      0      0      0      0      0]\n",
      " [     4    213      5      8      0      0      0      0      0      0]\n",
      " [     3      9      0      0      0      0      0      0      0      0]\n",
      " [     2      1      0      0      0      0      0      0      0      0]]\n",
      "Accuracy Using KNeighbors : 0.511838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.66      0.60    501209\n",
      "           1       0.46      0.42      0.44    422498\n",
      "           2       0.16      0.01      0.02     47622\n",
      "           3       0.11      0.01      0.01     21121\n",
      "           4       0.04      0.00      0.00      3885\n",
      "           5       0.58      0.02      0.04      1996\n",
      "           6       0.00      0.00      0.00      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.51      0.51      0.51   1000000\n",
      "   macro avg       0.19      0.11      0.11   1000000\n",
      "weighted avg       0.48      0.51      0.49   1000000\n",
      "\n",
      "[[331574 168519    883    197     15     21      0      0      0      0]\n",
      " [240295 179463   2025    621     79     12      2      0      0      1]\n",
      " [ 23705  23082    626    182     25      0      1      0      1      0]\n",
      " [  8405  12284    296    125     11      0      0      0      0      0]\n",
      " [  1220   2548     90     22      5      0      0      0      0      0]\n",
      " [  1536    415      0      0      0     45      0      0      0      0]\n",
      " [   505    835     61     19      4      0      0      0      0      0]\n",
      " [    47    156     20      7      0      0      0      0      0      0]\n",
      " [     6      6      0      0      0      0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0      0]]\n",
      "Accuracy Using Bagging with DT : 0.592428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69    501209\n",
      "           1       0.55      0.49      0.52    422498\n",
      "           2       0.27      0.03      0.06     47622\n",
      "           3       0.44      0.04      0.07     21121\n",
      "           4       0.10      0.00      0.01      3885\n",
      "           5       0.24      0.00      0.01      1996\n",
      "           6       0.31      0.00      0.01      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.59      0.59      0.59   1000000\n",
      "   macro avg       0.25      0.13      0.14   1000000\n",
      "weighted avg       0.57      0.59      0.57   1000000\n",
      "\n",
      "[[384152 116443    507     73     13     20      1      0      0      0]\n",
      " [212717 205811   3308    562     84      2      6      0      7      1]\n",
      " [ 13926  31779   1647    248     19      0      3      0      0      0]\n",
      " [  5281  14555    483    792      8      0      1      1      0      0]\n",
      " [   918   2876     61     14     14      0      0      0      1      1]\n",
      " [  1579    409      1      0      0      7      0      0      0      0]\n",
      " [   171   1084    107     54      3      0      5      0      0      0]\n",
      " [    20    153     20     37      0      0      0      0      0      0]\n",
      " [     5      7      0      0      0      0      0      0      0      0]\n",
      " [     1      2      0      0      0      0      0      0      0      0]]\n",
      "Accuracy Using AdaBoost : 0.491576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66    501209\n",
      "           1       0.00      0.00      0.00    422498\n",
      "           2       0.00      0.00      0.00     47622\n",
      "           3       0.00      0.00      0.00     21121\n",
      "           4       0.00      0.00      0.00      3885\n",
      "           5       0.00      0.00      0.00      1996\n",
      "           6       0.00      0.00      0.00      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.49      0.49      0.49   1000000\n",
      "   macro avg       0.05      0.10      0.07   1000000\n",
      "weighted avg       0.25      0.49      0.33   1000000\n",
      "\n",
      "[[491576      0      0      0      0      0      0      0      0   9633]\n",
      " [414414      0      0      0      0      0      0      0      0   8084]\n",
      " [ 46709      0      0      0      0      0      0      0      0    913]\n",
      " [ 20729      0      0      0      0      0      0      0      0    392]\n",
      " [  3853      0      0      0      0      0      0      0      0     32]\n",
      " [  1962      0      0      0      0      0      0      0      0     34]\n",
      " [  1402      0      0      0      0      0      0      0      0     22]\n",
      " [   227      0      0      0      0      0      0      0      0      3]\n",
      " [    12      0      0      0      0      0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0      0]]\n",
      "Accuracy Using Naive Bayes : 0.501209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67    501209\n",
      "           1       0.00      0.00      0.00    422498\n",
      "           2       0.00      0.00      0.00     47622\n",
      "           3       0.00      0.00      0.00     21121\n",
      "           4       0.00      0.00      0.00      3885\n",
      "           5       0.00      0.00      0.00      1996\n",
      "           6       0.00      0.00      0.00      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.50      0.50      0.50   1000000\n",
      "   macro avg       0.05      0.10      0.07   1000000\n",
      "weighted avg       0.25      0.50      0.33   1000000\n",
      "\n",
      "[[501209      0      0      0      0      0      0      0      0      0]\n",
      " [422498      0      0      0      0      0      0      0      0      0]\n",
      " [ 47622      0      0      0      0      0      0      0      0      0]\n",
      " [ 21121      0      0      0      0      0      0      0      0      0]\n",
      " [  3885      0      0      0      0      0      0      0      0      0]\n",
      " [  1996      0      0      0      0      0      0      0      0      0]\n",
      " [  1424      0      0      0      0      0      0      0      0      0]\n",
      " [   230      0      0      0      0      0      0      0      0      0]\n",
      " [    12      0      0      0      0      0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0      0]]\n",
      "Accuracy Using Decision Tree : 0.479308\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.56      0.57    501209\n",
      "           1       0.46      0.45      0.46    422498\n",
      "           2       0.09      0.11      0.10     47622\n",
      "           3       0.07      0.08      0.07     21121\n",
      "           4       0.02      0.03      0.03      3885\n",
      "           5       0.17      0.21      0.19      1996\n",
      "           6       0.01      0.02      0.02      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.48      0.48      0.48   1000000\n",
      "   macro avg       0.14      0.15      0.14   1000000\n",
      "weighted avg       0.49      0.48      0.48   1000000\n",
      "\n",
      "[[279622 189007  20823   7948   1644   1300    671     79     15    100]\n",
      " [184701 192231  28001  12738   2658    627   1235    156     76     75]\n",
      " [ 15909  23475   5244   1999    504     49    380     26     23     13]\n",
      " [  5942  11100   2041   1639    227      6    139     18      6      3]\n",
      " [   961   2104    440    208    127      3     37      1      3      1]\n",
      " [   878    520     31     12      2    413      0      0    112     28]\n",
      " [   274    721    259    110     25      0     32      2      1      0]\n",
      " [    33    111     41     40      3      0      2      0      0      0]\n",
      " [     4      4      1      0      0      3      0      0      0      0]\n",
      " [     1      0      0      0      0      2      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "# define models\n",
    "models = [RandomForestClassifier(n_estimators=100), KNeighborsClassifier(), BaggingClassifier(), AdaBoostClassifier(), GaussianNB(), tree.DecisionTreeClassifier(), svm.SVC(kernel='linear', C=1), OutputCodeClassifier(BaggingClassifier()), OneVsRestClassifier(svm.SVC(kernel='linear'))]\n",
    "\n",
    "# define model names\n",
    "model_names = [\"Random Forest\", \"KNeighbors\", \"Bagging with DT\", \"AdaBoost\", \"Naive Bayes\", \"Decision Tree\", \"Linear SVM\", \"OutputCodeClassifier with Linear SVM\", \"OneVsRestClassifier with Linear SVM\"]\n",
    "\n",
    "# run models\n",
    "for model, name in zip(models, model_names):\n",
    "    model.fit(X_train, Y_train.values.ravel())\n",
    "    \n",
    "    # make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # show arruracy\n",
    "    acc = accuracy_score(Y_test, predictions)\n",
    "    print(\"Accuracy Using\", name,\": \" + str(acc)+'\\n')\n",
    "    print(classification_report(Y_test, predictions))\n",
    "    print(confusion_matrix(Y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
