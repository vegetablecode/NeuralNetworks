{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each record is an example of a hand consisting of five playing cards drawn from a standard deck of 52. Each card is described using two attributes (suit and rank), for a total of 10 predictive attributes.\n",
    "\n",
    "* ranks (C1, C2, C3, C4, C5)    \n",
    "  - 1: Ace  \n",
    "  - 2-10: 2-10  \n",
    "  - 11: Jack  \n",
    "  - 12: Queen  \n",
    "  - 13: King  \n",
    "* suits (S1, S2, S3, S4, S5)   \n",
    "  - 1: Hearts  \n",
    "  - 2: Spades  \n",
    "  - 3: Diamonds  \n",
    "  - 4: Clubs  \n",
    "* hand  \n",
    "  - 0: Nothing in hand; not a recognized poker hand \n",
    "  - 1: One pair; one pair of equal ranks within five cards\n",
    "  - 2: Two pairs; two pairs of equal ranks within five cards\n",
    "  - 3: Three of a kind; three equal ranks within five cards\n",
    "  - 4: Straight; five cards, sequentially ranked with no gaps\n",
    "  - 5: Flush; five cards with the same suit\n",
    "  - 6: Full house; pair + different rank three of a kind\n",
    "  - 7: Four of a kind; four equal ranks within five cards\n",
    "  - 8: Straight flush; straight + flush\n",
    "  - 9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data: (1000000, 11)\n",
      "Training data: (25010, 11)\n",
      "-----\n",
      "Training Hand\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S1  C1  S2  C2  S3  C3  S4  C4  S5  C5  hand\n",
       "0   1  10   1  11   1  13   1  12   1   1     9\n",
       "1   2  11   2  13   2  10   2  12   2   1     9\n",
       "2   3  12   3  11   3  13   3  10   3   1     9\n",
       "3   4  10   4  11   4   1   4  13   4  12     9\n",
       "4   4   1   4  13   4  12   4  11   4  10     9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset location\n",
    "testing_data_location = \"./dataset/poker-hand-testing.data\"\n",
    "training_data_location = \"./dataset/poker-hand-training-true.data\"\n",
    "\n",
    "# assign column names to the dataset attributes\n",
    "names = ['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5','hand']\n",
    "\n",
    "# get testing & training data\n",
    "testing = pd.read_csv(testing_data_location, names=names, sep=',', header=None)\n",
    "training = pd.read_csv(training_data_location, names=names, sep=',', header=None)\n",
    "\n",
    "print(\"Testing data:\", testing.shape)\n",
    "print(\"Training data:\", training.shape)\n",
    "\n",
    "# show the first five columns of the training hand\n",
    "print(\"-----\")\n",
    "print(\"Training Hand\")\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Hand\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S1  C1  S2  C2  S3  C3  S4  C4  S5  C5  hand\n",
       "0   1   1   1  13   2   4   2   3   1  12     0\n",
       "1   3  12   3   2   3  11   4   5   2   5     1\n",
       "2   1   9   4   6   1   4   3   2   3   9     1\n",
       "3   1   4   3  13   2  13   2   1   3   6     1\n",
       "4   3  10   2   7   1   2   2  11   4   9     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first five columns of the testing hand\n",
    "print(\"Testing Hand\")\n",
    "testing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate dataset attributes (X) from Class (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training X\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S1  C1  S2  C2  S3  C3  S4  C4  S5  C5\n",
       "0   1  10   1  11   1  13   1  12   1   1\n",
       "1   2  11   2  13   2  10   2  12   2   1\n",
       "2   3  12   3  11   3  13   3  10   3   1\n",
       "3   4  10   4  11   4   1   4  13   4  12\n",
       "4   4   1   4  13   4  12   4  11   4  10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate first ten columns (X) from eleven'th column for training set\n",
    "X_train = training.iloc[:,0:10]\n",
    "Y_train = training.iloc[:,10]\n",
    "\n",
    "# ...for testing set\n",
    "X_test = testing.iloc[:,0:10]\n",
    "Y_test = testing.iloc[:,10]\n",
    "\n",
    "# show first five columns of training X\n",
    "print(\"training X\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9\n",
       "1    9\n",
       "2    9\n",
       "3    9\n",
       "4    9\n",
       "Name: hand, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first five columns of training Y\n",
    "print(\"training Y\")\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show unique Class values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8, 1, 0, 4, 3, 2, 5, 6, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show unique Class categories\n",
    "Y_train.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# fit only for training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# transform training and testing data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3 layers of 10 nodes each + 1000 iterations\n",
    "mlp = MLPClassifier(solver='adam', hidden_layer_sizes=(30, 30), max_iter=2000, activation='tanh', learning_rate_init=0.02)\n",
    "\n",
    "# train algorithm on training data\n",
    "mlp.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# make predictions\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "acc = accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[500373     50      0      0    746      8      0      0      1     31]\n",
      " [     0 422458     20      0      0      3      0      0     17      0]\n",
      " [     0      2  47513    107      0      0      0      0      0      0]\n",
      " [     0      0     82  21008      0      0     30      1      0      0]\n",
      " [  3020     99      0      0    761      0      0      0      2      3]\n",
      " [  1623      2      0      0      2    324      0      0      6     39]\n",
      " [     0      0      0    282      0      0   1142      0      0      0]\n",
      " [     0      0      0     22      0      0     85    123      0      0]\n",
      " [     5      0      0      0      4      1      0      0      2      0]\n",
      " [     1      0      0      0      0      2      0      0      0      0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    501209\n",
      "           1       1.00      1.00      1.00    422498\n",
      "           2       1.00      1.00      1.00     47622\n",
      "           3       0.98      0.99      0.99     21121\n",
      "           4       0.50      0.20      0.28      3885\n",
      "           5       0.96      0.16      0.28      1996\n",
      "           6       0.91      0.80      0.85      1424\n",
      "           7       0.99      0.53      0.69       230\n",
      "           8       0.07      0.17      0.10        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.99      0.99      0.99   1000000\n",
      "   macro avg       0.74      0.59      0.62   1000000\n",
      "weighted avg       0.99      0.99      0.99   1000000\n",
      "\n",
      "Accuracy Using MLP: 0.993704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,predictions))\n",
    "print(classification_report(Y_test, predictions))\n",
    "print(\"Accuracy Using MLP: \" + str(acc)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with the other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Using Random Forest : 0.614143\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.81      0.71    501209\n",
      "           1       0.58      0.49      0.53    422498\n",
      "           2       0.40      0.00      0.01     47622\n",
      "           3       0.48      0.00      0.00     21121\n",
      "           4       0.27      0.00      0.00      3885\n",
      "           5       1.00      0.00      0.01      1996\n",
      "           6       0.00      0.00      0.00      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.61      0.61      0.61   1000000\n",
      "   macro avg       0.34      0.13      0.13   1000000\n",
      "weighted avg       0.59      0.61      0.58   1000000\n",
      "\n",
      "[[404899  96297      9      3      0      0      0      0      0      1]\n",
      " [213270 208986    210     24      8      0      0      0      0      0]\n",
      " [ 12265  35143    199     14      0      0      1      0      0      0]\n",
      " [  3587  17442     42     49      0      0      0      1      0      0]\n",
      " [   389   3488      5      0      3      0      0      0      0      0]\n",
      " [  1812    177      0      0      0      7      0      0      0      0]\n",
      " [    75   1318     22      9      0      0      0      0      0      0]\n",
      " [     2    220      5      3      0      0      0      0      0      0]\n",
      " [     6      6      0      0      0      0      0      0      0      0]\n",
      " [     2      1      0      0      0      0      0      0      0      0]]\n",
      "Accuracy Using KNeighbors : 0.511838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.66      0.60    501209\n",
      "           1       0.46      0.42      0.44    422498\n",
      "           2       0.16      0.01      0.02     47622\n",
      "           3       0.11      0.01      0.01     21121\n",
      "           4       0.04      0.00      0.00      3885\n",
      "           5       0.58      0.02      0.04      1996\n",
      "           6       0.00      0.00      0.00      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.51      0.51      0.51   1000000\n",
      "   macro avg       0.19      0.11      0.11   1000000\n",
      "weighted avg       0.48      0.51      0.49   1000000\n",
      "\n",
      "[[331574 168519    883    197     15     21      0      0      0      0]\n",
      " [240295 179463   2025    621     79     12      2      0      0      1]\n",
      " [ 23705  23082    626    182     25      0      1      0      1      0]\n",
      " [  8405  12284    296    125     11      0      0      0      0      0]\n",
      " [  1220   2548     90     22      5      0      0      0      0      0]\n",
      " [  1536    415      0      0      0     45      0      0      0      0]\n",
      " [   505    835     61     19      4      0      0      0      0      0]\n",
      " [    47    156     20      7      0      0      0      0      0      0]\n",
      " [     6      6      0      0      0      0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0      0]]\n",
      "Accuracy Using Bagging with DT : 0.595502\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69    501209\n",
      "           1       0.55      0.49      0.52    422498\n",
      "           2       0.28      0.04      0.07     47622\n",
      "           3       0.40      0.04      0.07     21121\n",
      "           4       0.15      0.01      0.01      3885\n",
      "           5       0.33      0.00      0.01      1996\n",
      "           6       0.23      0.00      0.01      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.60      0.60      0.60   1000000\n",
      "   macro avg       0.26      0.13      0.14   1000000\n",
      "weighted avg       0.57      0.60      0.57   1000000\n",
      "\n",
      "[[384985 115679    450     69     13     13      0      0      0      0]\n",
      " [210442 207894   3388    685     78      5      5      1      0      0]\n",
      " [ 13418  32060   1811    311     13      0      9      0      0      0]\n",
      " [  4953  14818    561    777      5      0      6      1      0      0]\n",
      " [  1037   2756     62      8     20      0      0      0      1      1]\n",
      " [  1574    412      0      0      0      9      0      0      0      1]\n",
      " [   128   1105    123     61      1      0      6      0      0      0]\n",
      " [    15    155     29     31      0      0      0      0      0      0]\n",
      " [     5      6      1      0      0      0      0      0      0      0]\n",
      " [     1      2      0      0      0      0      0      0      0      0]]\n",
      "Accuracy Using AdaBoost : 0.491576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66    501209\n",
      "           1       0.00      0.00      0.00    422498\n",
      "           2       0.00      0.00      0.00     47622\n",
      "           3       0.00      0.00      0.00     21121\n",
      "           4       0.00      0.00      0.00      3885\n",
      "           5       0.00      0.00      0.00      1996\n",
      "           6       0.00      0.00      0.00      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.49      0.49      0.49   1000000\n",
      "   macro avg       0.05      0.10      0.07   1000000\n",
      "weighted avg       0.25      0.49      0.33   1000000\n",
      "\n",
      "[[491576      0      0      0      0      0      0      0      0   9633]\n",
      " [414414      0      0      0      0      0      0      0      0   8084]\n",
      " [ 46709      0      0      0      0      0      0      0      0    913]\n",
      " [ 20729      0      0      0      0      0      0      0      0    392]\n",
      " [  3853      0      0      0      0      0      0      0      0     32]\n",
      " [  1962      0      0      0      0      0      0      0      0     34]\n",
      " [  1402      0      0      0      0      0      0      0      0     22]\n",
      " [   227      0      0      0      0      0      0      0      0      3]\n",
      " [    12      0      0      0      0      0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0      0]]\n",
      "Accuracy Using Naive Bayes : 0.501209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67    501209\n",
      "           1       0.00      0.00      0.00    422498\n",
      "           2       0.00      0.00      0.00     47622\n",
      "           3       0.00      0.00      0.00     21121\n",
      "           4       0.00      0.00      0.00      3885\n",
      "           5       0.00      0.00      0.00      1996\n",
      "           6       0.00      0.00      0.00      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.50      0.50      0.50   1000000\n",
      "   macro avg       0.05      0.10      0.07   1000000\n",
      "weighted avg       0.25      0.50      0.33   1000000\n",
      "\n",
      "[[501209      0      0      0      0      0      0      0      0      0]\n",
      " [422498      0      0      0      0      0      0      0      0      0]\n",
      " [ 47622      0      0      0      0      0      0      0      0      0]\n",
      " [ 21121      0      0      0      0      0      0      0      0      0]\n",
      " [  3885      0      0      0      0      0      0      0      0      0]\n",
      " [  1996      0      0      0      0      0      0      0      0      0]\n",
      " [  1424      0      0      0      0      0      0      0      0      0]\n",
      " [   230      0      0      0      0      0      0      0      0      0]\n",
      " [    12      0      0      0      0      0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0      0]]\n",
      "Accuracy Using Decision Tree : 0.47961\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.56      0.57    501209\n",
      "           1       0.46      0.45      0.46    422498\n",
      "           2       0.09      0.11      0.10     47622\n",
      "           3       0.07      0.08      0.07     21121\n",
      "           4       0.03      0.04      0.03      3885\n",
      "           5       0.19      0.23      0.21      1996\n",
      "           6       0.01      0.02      0.02      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.48      0.48      0.48   1000000\n",
      "   macro avg       0.14      0.15      0.15   1000000\n",
      "weighted avg       0.49      0.48      0.48   1000000\n",
      "\n",
      "[[279917 189279  20433   7951   1593   1257    574     99     18     88]\n",
      " [184855 192057  27813  12893   2755    612   1188    189     76     60]\n",
      " [ 15950  23357   5342   2004    520     42    349     33     16      9]\n",
      " [  5886  11080   2019   1670    267      7    152     27      7      6]\n",
      " [   967   2107    395    227    136      1     36      2     10      4]\n",
      " [   878    523     37      5      1    458      0      0     70     24]\n",
      " [   291    726    243    104     26      0     30      4      0      0]\n",
      " [    26    110     42     45      4      0      3      0      0      0]\n",
      " [     3      5      1      0      0      3      0      0      0      0]\n",
      " [     1      0      0      0      0      2      0      0      0      0]]\n",
      "Accuracy Using Linear SVM : 0.501209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67    501209\n",
      "           1       0.00      0.00      0.00    422498\n",
      "           2       0.00      0.00      0.00     47622\n",
      "           3       0.00      0.00      0.00     21121\n",
      "           4       0.00      0.00      0.00      3885\n",
      "           5       0.00      0.00      0.00      1996\n",
      "           6       0.00      0.00      0.00      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.50      0.50      0.50   1000000\n",
      "   macro avg       0.05      0.10      0.07   1000000\n",
      "weighted avg       0.25      0.50      0.33   1000000\n",
      "\n",
      "[[501209      0      0      0      0      0      0      0      0      0]\n",
      " [422498      0      0      0      0      0      0      0      0      0]\n",
      " [ 47622      0      0      0      0      0      0      0      0      0]\n",
      " [ 21121      0      0      0      0      0      0      0      0      0]\n",
      " [  3885      0      0      0      0      0      0      0      0      0]\n",
      " [  1996      0      0      0      0      0      0      0      0      0]\n",
      " [  1424      0      0      0      0      0      0      0      0      0]\n",
      " [   230      0      0      0      0      0      0      0      0      0]\n",
      " [    12      0      0      0      0      0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0      0]]\n",
      "Accuracy Using OutputCodeClassifier with Linear SVM : 0.604919\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71    501209\n",
      "           1       0.58      0.45      0.51    422498\n",
      "           2       0.37      0.01      0.02     47622\n",
      "           3       0.48      0.03      0.05     21121\n",
      "           4       0.15      0.00      0.00      3885\n",
      "           5       1.00      0.00      0.01      1996\n",
      "           6       0.00      0.00      0.00      1424\n",
      "           7       0.04      0.00      0.01       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.60      0.60      0.60   1000000\n",
      "   macro avg       0.32      0.13      0.13   1000000\n",
      "weighted avg       0.59      0.60      0.57   1000000\n",
      "\n",
      "[[415019  86168     14      4      1      0      0      1      1      1]\n",
      " [232779 188817    608    221     34      0      0     13     25      1]\n",
      " [ 17268  29563    537    229      5      0      0      4     16      0]\n",
      " [  4510  15857    204    531      3      0      0      6      9      1]\n",
      " [   750   3084     36      7      8      0      0      0      0      0]\n",
      " [  1772    212      0      0      0      6      4      0      0      2]\n",
      " [   186   1098     56     82      1      0      0      1      0      0]\n",
      " [    10    175     11     32      0      0      0      1      1      0]\n",
      " [     3      8      0      0      0      0      1      0      0      0]\n",
      " [     2      1      0      0      0      0      0      0      0      0]]\n",
      "Accuracy Using OneVsRestClassifier with Linear SVM : 0.462744\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.91      0.65    501209\n",
      "           1       0.42      0.02      0.03    422498\n",
      "           2       0.00      0.00      0.00     47622\n",
      "           3       0.02      0.01      0.01     21121\n",
      "           4       0.00      0.06      0.01      3885\n",
      "           5       0.00      0.00      0.00      1996\n",
      "           6       0.00      0.00      0.00      1424\n",
      "           7       0.00      0.00      0.00       230\n",
      "           8       0.00      0.00      0.00        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.46      0.46      0.46   1000000\n",
      "   macro avg       0.09      0.10      0.07   1000000\n",
      "weighted avg       0.43      0.46      0.34   1000000\n",
      "\n",
      "[[455629   8168     22   6155  22429   2048    277    734   5688     59]\n",
      " [384842   6716      7   4816  19163   1459    206    504   4708     77]\n",
      " [ 43483    730      0    472   2184    153     20     59    516      5]\n",
      " [ 19376    327      1    182    964     59      4      7    190     11]\n",
      " [  3566     34      0     22    215     12      0      0     35      1]\n",
      " [  1762      0      0      7    156      2      8      4     57      0]\n",
      " [  1311     20      0     10     67      4      0      1     11      0]\n",
      " [   215      2      0      3     10      0      0      0      0      0]\n",
      " [    11      0      0      0      1      0      0      0      0      0]\n",
      " [     3      0      0      0      0      0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "# define models\n",
    "models = [RandomForestClassifier(n_estimators=100), KNeighborsClassifier(), BaggingClassifier(), AdaBoostClassifier(), GaussianNB(), tree.DecisionTreeClassifier(), svm.SVC(kernel='linear', C=1), OutputCodeClassifier(BaggingClassifier()), OneVsRestClassifier(svm.SVC(kernel='linear'))]\n",
    "\n",
    "# define model names\n",
    "model_names = [\"Random Forest\", \"KNeighbors\", \"Bagging with DT\", \"AdaBoost\", \"Naive Bayes\", \"Decision Tree\", \"Linear SVM\", \"OutputCodeClassifier with Linear SVM\", \"OneVsRestClassifier with Linear SVM\"]\n",
    "\n",
    "# run models\n",
    "for model, name in zip(models, model_names):\n",
    "    model.fit(X_train, Y_train.values.ravel())\n",
    "    \n",
    "    # make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # show arruracy\n",
    "    acc = accuracy_score(Y_test, predictions)\n",
    "    print(\"Accuracy Using\", name,\": \" + str(acc)+'\\n')\n",
    "    print(classification_report(Y_test, predictions))\n",
    "    print(confusion_matrix(Y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
