{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"#-*- coding: latin1 -*-\nimport numpy as np\nimport pandas as pd\nimport os\nfrom matplotlib import pyplot as plt\n\nfrom keras.datasets import cifar10\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.optimizers import SGD\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\n\nplt.rcParams['figure.figsize'] = [15, 10]","execution_count":66,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Description"},{"metadata":{},"cell_type":"markdown","source":"- CIFAR-10 jest zbiorem zawierającym 60.000 zdjęć, każde w rozmiarach 32x32 pikseli. Zdjęcia można podzielić na 10 klas (6000 zdjęć każdej klasy). Zbiór uczący składa się z 50.000 instancji, zbiór testowy z 10.000.\n- Instancje podzielone są na 5 batchy uczących i 1 testujący. Każdy batch zawiera 10.000 zdjęć.\n- Pojedynczy batch zawiera 1000 losowo wybranych zdjęć z każdej klasy.\n- Klasy zdjęć:  \n  - airplane\n  - automobile\n  - bird\n  - cat\n  - deer\n  - dog\n  - frog\n  - horse\n  - ship\n  - truck"},{"metadata":{},"cell_type":"markdown","source":"Używany w dalszej części projektu termin \"skuteczność klasyfikacji\" oznacza stosunek poprawnie sklasyfikowanych obrazów zbioru testowego, w stosunku do całkowitej liczby elementów w tym zbiorze pomnożony przez 100%. Przykładowo \"skuteczność 80%\" oznacza, że w 80%-tach przypadków sieć poprawnie sklasyfikowała wybrany obraz znajdujący się w zbiorze testowym.\n\nUżywany w dalszej części projektu termin \"epoka\" lub \"iteracja\" oznacza proces przetworzenia wszystkich elementów zbioru uczącego."},{"metadata":{},"cell_type":"markdown","source":"# Helper functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load train and test dataset\ndef load_dataset():\n    # load dataset\n    (trainX, trainY), (testX, testY) = cifar10.load_data()\n    \n    # one hot encode target values (transform integer into a 10 element binary vector with a a1 for the class index of the value)\n    trainY = np_utils.to_categorical(trainY)\n    testY = np_utils.to_categorical(testY)\n    return trainX, trainY, testX, testY\n\n\n# scale pixels\ndef scale_pixels(train, test):\n    # convert: integers -> float32\n    train_norm = train.astype('float32')\n    test_norm = test.astype('float32')\n    \n    # normalize to range 0-1\n    train_norm = train_norm / 255.0\n    test_norm = test_norm / 255.0\n    \n    # return normalized images\n    return train_norm, test_norm\n\n\n# plot diagnostic learning curves\ndef show_summary(history):\n    # plot loss\n    plt.subplot(211)\n    plt.title('Cross Entropy Loss')\n    plt.plot(history.history['loss'], color='blue', label='train')\n    plt.plot(history.history['val_loss'], color='orange', label='test')\n    # plot accuracy\n    plt.subplot(212)\n    plt.title('Classification Accuracy')\n    plt.plot(history.history['acc'], color='blue', label='train')\n    plt.plot(history.history['val_acc'], color='orange', label='test')\n\n    \n# run test\ndef run_test(mod, iterations = None):\n    # load dataset\n    trainX, trainY, testX, testY = load_dataset()\n    \n    # scale pixels\n    trainX, testX = scale_pixels(trainX, testX)\n    \n    if iterations is None:\n        iterations = 100\n    \n    # fit model\n    history = mod.fit(trainX, trainY, \n                        epochs = iterations, \n                        batch_size = 64, \n                        validation_data = (testX, testY), \n                        verbose = 1)\n\n    # evaluate model\n    _, acc = mod.evaluate(testX, testY, verbose = 0)\n\n    # print accuracy\n    print('Accuracy (on testing set): > %.3f' % (acc * 100.0))\n    \n    # return history\n    return history","execution_count":67,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the dataset\ntrainX, trainY, testX, testY = load_dataset()\n\n# dataset summary\nprint('Training data: X = %s, y = %s' % (trainX.shape, trainY.shape))\nprint('Testing data: X = %s, y = %s' % (testX.shape, testY.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Show example images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot sample images\nfor i in range(9):\n    # define subplot\n    plt.subplot(330 + 1 + i)\n    # plot raw pixel data\n    plt.imshow(trainX[i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare pixel data"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX, trainY = scale_pixels(trainX, trainY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define base model (1 VGG block)"},{"metadata":{},"cell_type":"markdown","source":"Na początku zdefiniowano podstawowy model VGG, który składa się z:\n- (1) dwóch warstw konwolucyjnych o rozmiarach 3x3,\n- (2) jednej warstwy dokonującej max-pooling,\n- (3) dwóch warstw w pełni połączonych\n\nWarstwy (1) i (2) tworzą pewnego rodzaju \"blok\", który może być powielany, przy czym liczba filtrów w każdym bloku będzie wzrastała dwukrotnie wraz z każdym kolejnym blokiem.\n\nPadding został użyty na warstwach konwolucyjnych po to, by upewnić się, że rozmiary warstw wyjściowych będą takie same jak rozmiary warstwy wejściowej.\n\nUżytym algorytmem optymalizującym był SGD (Stochastic Gradient Descent)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define cnn model\ndef define_model_v1():\n    # create sequential model\n    model = Sequential()\n    \n    # add convolution\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    \n    # add pooling\n    model.add(MaxPooling2D((2, 2)))\n    \n    # flatten (flattens input into a single vector)\n    model.add(Flatten())\n    \n    # fully connected layer (128 units, ReLU activation function)\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    \n    # fully connected layer (10 units, softmax activation function)\n    model.add(Dense(10, activation='softmax'))\n    \n    # compile model\n    opt = SGD(lr = 0.001, momentum = 0.9)\n    model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    \n    return model\n\nmodel = define_model_v1()\n\n# run test\nhistory = run_test(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show summary\nshow_summary(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Jak widać powyżej, sieć neuronowa oparta o model zbudowany z jednego bloku VGG przeprowadziła poprawną klasyfikację obrazu w 66.6%. Jest to dobry wynik, zważając na to, że zbiór zawiera aż 10 różnych klas, więc prawdopodobieństwo trafienia \"na ślepo\" wynosi 10%.\n\nJak widać na powyższych wykresach, dość szybko następuje zjawisko przeuczenia i już po 15 iteracjach wartość funkcji straty dla danych testowych zaczyna gwałtownie rosnąć, pomimo że skuteczność klasyfikacji sieci dla danych ze zbioru uczącego wynosi w tym czasie dopiero ok. 85%.\n\nNajlepsze wyniki dla tego zbioru danych uzyskiwane przy użyciu konwolucyjnych sieci neuronowych wynosiły ponad 90%. Jest to wynik znacznie większy, niż ten uzyskany powyżej, dlatego w kolejnych etapach projektu zwiększono liczbę bloków VGG i zbadano ich wpływ na skuteczność klasyfikacji."},{"metadata":{},"cell_type":"markdown","source":"# Define modified model (with 2 VGG blocks)"},{"metadata":{},"cell_type":"markdown","source":"W kolejnej części projektu zmodyfikowano poprzedni model, dodając do niego kolejny blok VGG i porównano wyniki. Jak wspomnianio wcześniej, podczas dokładania kolejnych bloków VGG, liczba zastosowanych filtrów będzie zwiększana dwukrotnie z każdym dodanym blokiem."},{"metadata":{"trusted":true},"cell_type":"code","source":"# define cnn model\ndef define_model_v2():\n    # create sequential model\n    model = Sequential()\n    \n    # add convolution (1st VGG block)\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    \n    # add pooling\n    model.add(MaxPooling2D((2, 2)))\n    \n    # add convolution (2st VGG block)\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    \n    # add pooling\n    model.add(MaxPooling2D((2, 2)))\n    \n    # flatten (flattens input into a single vector)\n    model.add(Flatten())\n    \n    # fully connected layer (128 units, ReLU activation function)\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    \n    # fully connected layer (10 units, softmax activation function)\n    model.add(Dense(10, activation='softmax'))\n    \n    # compile model\n    opt = SGD(lr = 0.001, momentum = 0.9)\n    model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    \n    return model\n\nmodel = define_model_v2()\n\n# run test\nhistory = run_test(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show summary\nshow_summary(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Jak widać powyżej, rozbudowanie modelu o jeden blok VGG nieznacznie zwiększył skuteczność sieci (do ok. 71%), jednak nadal dosyć szybko pojawia się zjawisko przeuczenia.\n\nW kolejnym etapie do sieci dodano jeszcze jeden blok i zbadano, czy skuteczność wykrywania ponownie się polepszy."},{"metadata":{},"cell_type":"markdown","source":"# Define modified model (with 3 VGG blocks)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define cnn model\ndef define_model_v3():\n    # create sequential model\n    model = Sequential()\n    \n    # add convolution (1st VGG block)\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    \n    # add pooling\n    model.add(MaxPooling2D((2, 2)))\n    \n    # add convolution (2st VGG block)\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    \n    # add pooling\n    model.add(MaxPooling2D((2, 2)))\n    \n    # add convolution (3st VGG block)\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    \n    # add pooling\n    model.add(MaxPooling2D((2, 2)))\n    \n    # flatten (flattens input into a single vector)\n    model.add(Flatten())\n    \n    # fully connected layer (128 units, ReLU activation function)\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    \n    # fully connected layer (10 units, softmax activation function)\n    model.add(Dense(10, activation='softmax'))\n    \n    # compile model\n    opt = SGD(lr = 0.001, momentum = 0.9)\n    model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    \n    return model\n\nmodel = define_model_v3()\n\n# run test\nhistory = run_test(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show summary\nshow_summary(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Skuteczność sieci z trzema blokami VGG wynosi ok. 74%, jednak ciągle widoczne jest tu zjawisko przeuczenia, które występuje już po niecałych 20-tu iteracjach."},{"metadata":{},"cell_type":"markdown","source":"# Define improved model (with 3 VGG + dropout)"},{"metadata":{},"cell_type":"markdown","source":"W kolejnym etapie projektu dodano do poprzedniej sieci \"Dropout\", który polega na usuwaniu pewnych połączeń pomiędzy neuronami w sieci, z pewnym prawdopodobieństwem. Zabieg ten ma na celu obniżenie wrażliwości modelu na przeuczenie. Jest to forma regularyzacji modelu. Dzięki zastosowaniu warstwy \"Dropout\", sieć będzie starała się dostrzegać niezależne cechy i brak jednej z nich nie będzie wtedy problemem. Powinno to znacznie obniżyć podatność sieci na przeuczenie.\n\nModel z punktu wyżej zmodyfikowano poprzez dodanie warstw \"Dropout\" po każdym poolingu oraz po warstwie w pełni połączonej. \"Dropout rate\" ustawiony został na 20% (usuwane jest 20% połączeń)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# define cnn model\ndef define_model_v3_dropout():\n    # create sequential model\n    model = Sequential()\n    \n    # add convolution (1st VGG block)\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    \n    # add pooling\n    model.add(MaxPooling2D((2, 2)))\n    \n    # add dropout\n    model.add(Dropout(0.2))\n    \n    # add convolution (2st VGG block)\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    \n    # add pooling\n    model.add(MaxPooling2D((2, 2)))\n    \n    # add dropout\n    model.add(Dropout(0.2))\n    \n    # add convolution (3st VGG block)\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    \n    # add pooling\n    model.add(MaxPooling2D((2, 2)))\n    \n    # add dropout\n    model.add(Dropout(0.2))\n    \n    # flatten (flattens input into a single vector)\n    model.add(Flatten())\n    \n    # fully connected layer (128 units, ReLU activation function)\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    \n    # add dropout\n    model.add(Dropout(0.2))\n    \n    # fully connected layer (10 units, softmax activation function)\n    model.add(Dense(10, activation='softmax'))\n    \n    # compile model\n    opt = SGD(lr = 0.001, momentum = 0.9)\n    model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    \n    return model\n\nmodel = define_model_v3_dropout()\n\n# run test\nhistory = run_test(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show summary\nshow_summary(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Jak widać powyżej, dodanie \"Dropout\"'ów znacznie poprawiło skuteczność sieci dla danych testowych (ok. 83%), a zjawisko przeuczenia sieci jest już praktycznie niewidoczne. "},{"metadata":{},"cell_type":"markdown","source":"# Define improved model (with 3 VGG + dropout + batch normalization)"},{"metadata":{},"cell_type":"markdown","source":"Przy każdym poprzednim modelu, sieć trenowana była w 100 iteracjach (epokach). W następnym etapie projektu zwiększono tę liczbę, by sprawdzić czy model będzie w stanie jeszcze bardziej zwiększyć swoją dokładność.\n\nW poprzednim punkcie zlikwidowane zostało zjawisko overfittingu i wartość funkcji straty nie rośnie nawet w setnej epoce, dlatego można bezpiecznie zwiększyć ilość iteracji i sprawdzić jak zachowa się model.\n\nW celu przyspieszenia procesu nauki przy zwiększonej liczbie epok, zastosowano normalizację batch'u. Normalizacja batch'u jest techniką, która przyspiesza proces nauki i zwiększa jej stabilność. Używana jest to normalizacji warstwy wejściowej poprzez regulację i skalowanie funkcji aktywacji.\n\nW celu zwiększenia regularyzacji, zwiększano również stopiniowo wartość \"Dropout\"'u w każdej warstwie.\n\nLiczbę epok zwiększono do 400."},{"metadata":{"trusted":true},"cell_type":"code","source":"# define cnn model\ndef define_model_v3_dropout_normalization():\n    # create sequential model\n    model = Sequential()\n    \n    # add convolution (1st VGG block)\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    \n    # add pooling\n    model.add(MaxPooling2D((2, 2)))\n    \n    # add dropout\n    model.add(Dropout(0.2))\n    \n    # add convolution (2st VGG block)\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    \n    # add pooling\n    model.add(MaxPooling2D((2, 2)))\n    \n    # add dropout\n    model.add(Dropout(0.3))\n    \n    # add convolution (3st VGG block)\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(BatchNormalization())\n    \n    # add pooling\n    model.add(MaxPooling2D((2, 2)))\n    \n    # add dropout\n    model.add(Dropout(0.4))\n    \n    # flatten (flattens input into a single vector)\n    model.add(Flatten())\n    \n    # fully connected layer (128 units, ReLU activation function)\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(BatchNormalization())\n    \n    # add dropout\n    model.add(Dropout(0.5))\n    \n    # fully connected layer (10 units, softmax activation function)\n    model.add(Dense(10, activation='softmax'))\n    model.add(BatchNormalization())\n    \n    # compile model\n    opt = SGD(lr = 0.001, momentum = 0.9)\n    model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    \n    return model\n\nmodel = define_model_v3_dropout_normalization()\n\n# run test\nhistory = run_test(model, 100)","execution_count":null,"outputs":[{"output_type":"stream","text":"Train on 50000 samples, validate on 10000 samples\nEpoch 1/100\n50000/50000 [==============================] - 14s 278us/step - loss: 8.9506 - acc: 0.1508 - val_loss: 11.4392 - val_acc: 0.1141\nEpoch 2/100\n50000/50000 [==============================] - 11s 229us/step - loss: 10.7016 - acc: 0.1111 - val_loss: 11.3754 - val_acc: 0.1037\nEpoch 3/100\n50000/50000 [==============================] - 11s 230us/step - loss: 11.0724 - acc: 0.0971 - val_loss: 11.0436 - val_acc: 0.0860\nEpoch 4/100\n50000/50000 [==============================] - 11s 228us/step - loss: 10.7972 - acc: 0.0857 - val_loss: 10.6398 - val_acc: 0.0761\nEpoch 5/100\n50000/50000 [==============================] - 12s 232us/step - loss: 9.1851 - acc: 0.0831 - val_loss: 6.7262 - val_acc: 0.0807\nEpoch 6/100\n50000/50000 [==============================] - 12s 230us/step - loss: 6.8007 - acc: 0.0854 - val_loss: 6.6442 - val_acc: 0.0990\nEpoch 7/100\n50000/50000 [==============================] - 11s 229us/step - loss: 6.8661 - acc: 0.0981 - val_loss: 7.6137 - val_acc: 0.0925\nEpoch 8/100\n50000/50000 [==============================] - 11s 229us/step - loss: 7.6116 - acc: 0.0911 - val_loss: 7.0684 - val_acc: 0.0947\nEpoch 9/100\n50000/50000 [==============================] - 11s 228us/step - loss: 7.5165 - acc: 0.0924 - val_loss: 6.7584 - val_acc: 0.0967\nEpoch 10/100\n50000/50000 [==============================] - 12s 231us/step - loss: 7.2723 - acc: 0.0938 - val_loss: 6.6586 - val_acc: 0.1008\nEpoch 11/100\n50000/50000 [==============================] - 12s 230us/step - loss: 7.3230 - acc: 0.0958 - val_loss: 5.8246 - val_acc: 0.1126\nEpoch 12/100\n50000/50000 [==============================] - 11s 228us/step - loss: 6.0224 - acc: 0.1057 - val_loss: 5.7922 - val_acc: 0.1134\nEpoch 13/100\n50000/50000 [==============================] - 11s 228us/step - loss: 5.5432 - acc: 0.1100 - val_loss: 5.7755 - val_acc: 0.1139\nEpoch 14/100\n50000/50000 [==============================] - 11s 228us/step - loss: 5.4754 - acc: 0.1100 - val_loss: 5.7719 - val_acc: 0.1140\nEpoch 15/100\n50000/50000 [==============================] - 11s 228us/step - loss: 5.5376 - acc: 0.1094 - val_loss: 5.7480 - val_acc: 0.1130\nEpoch 16/100\n17728/50000 [=========>....................] - ETA: 6s - loss: 5.5560 - acc: 0.1117","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show summary\nshow_summary(history)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}